{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Project on MMA Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-14T13:02:11.088918Z",
     "iopub.status.busy": "2023-09-14T13:02:11.086743Z",
     "iopub.status.idle": "2023-09-14T13:02:11.128161Z"
    }
   },
   "source": [
    "Mixed Martial Arts is a very unpredictable sport, with analysts having a hard time picking out eventual winners, especially in the UFC organization. However, can we use/create Machine Learning models to aid those experts in making more informed decisions?\n",
    "\n",
    "In this project, I explore a large UFC database and utilise a range of models to find a model which accurately predicts fight outcomes.\n",
    "\n",
    "Some data cleaning and feature engineering was required first, which was then followed by experimentation of the models.\n",
    "\n",
    "Information on the maning of variables are available at the end.\n",
    "\n",
    "I do not own this data set, it was scraped using Python, this is available on GitHub:\n",
    "\n",
    "https://github.com/remypereira99/UFC-Web-Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explaining the Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ufc_fights:\n",
    "* event_id - Secondary key from ufc_events\\\n",
    "* referee - Referee of the fight\\\n",
    "* f_1 - Fighter 1\\\n",
    "* f_2 - Fighter 2\\\n",
    "* winner - Winner of the fight\\\n",
    "* num_rounds - Number of rounds\\\n",
    "* title_fight - Boolean for whether fight is a title fight or not\\\n",
    "* weight_class - Weight class of the fight\\\n",
    "* gender - Male or female fight\\\n",
    "* result - How did the fight end, e.g. decision, KO\\\n",
    "* result_details - Specific details of how the fight ended, e.g. KO by elbows, split decision\\\n",
    "* finish_round - What round did the fight finish\\\n",
    "* finish_time - What minute and second did the fight finish in that round (m:ss)\\\n",
    "* fight_url - URL used to scrape fight data from ufcstats.com\\\n",
    "\n",
    "For ufc_stats:\n",
    "* fight_id - Foreign key from ufc_fights\\\n",
    "* fighter_id - Foreign key from ufc_fighters\\\n",
    "* Knockdowns - No. of knockdowns landed \\\n",
    "* total_strikes_att - No. of strikes attempted\\\n",
    "* total_strikes_succ - No. of successful strikes\\\n",
    "* sig_strikes_att - No. of significant strikes attempted\\\n",
    "* sig_strikes_succ - No. of significant strikes successful\\\n",
    "* takedown_att - No. of takedown attempts\\\n",
    "* takedown_succ - No. of successful takedowns\\\n",
    "* submission_att - No. of submission attempts\\\n",
    "* reversals - No. of reversals\\\n",
    "* ctrl_time - Control time \\\n",
    "* fighter_age - Age of the fighter\\\n",
    "* winner - Boolean for whether fighter won or lost\\\n",
    "\n",
    "For ufc_fighters:\n",
    "* fighter_id - Primary key for ufc_fighters, unique for each fighter\\\n",
    "* fighter_f_name - Fighter first name\\\n",
    "* fighter_l_name - Fighter last name\\\n",
    "* fighter_nickname - Fighter nickname\\\n",
    "* fighter_height_cm - Fighter height in cm\\\n",
    "* fighter_weight_lbs - Fighter weight in lbs \\\n",
    "* fighter_reach_cm - Fighter reach in cm\\\n",
    "* fighter_stance - Fighter stance - e.g. southpaw, orthodox\\\n",
    "* fighter_dob - Fighter date of birth\\\n",
    "* fighter_w - No. of wins (at the time of scraping)\\\n",
    "* fighter_l - No. of losses (at the time of scraping)\\\n",
    "* fighter_d - No. of draws (at the time of scraping)\\\n",
    "* fighter_nc_dq - No. of no contests or disqualifications (at the time of scraping)\\\n",
    "* fighter_url - URL used to scrape fighter data from ufcstats.com}\n",
    "\n",
    "The rest of the variables will be explained throughout the notebook, with a bit of intuition needed to understand the abbreviations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-15T14:07:10.693781Z",
     "iopub.status.busy": "2023-09-15T14:07:10.691817Z",
     "iopub.status.idle": "2023-09-15T14:07:10.858174Z"
    },
    "trusted": true,
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Load up Required Datasets\n",
    "ufc_fights <- read.csv('/kaggle/input/mma-dataset-2023-ufc/ufc_fights.csv')\n",
    "ufc_stats <- read.csv('/kaggle/input/mma-dataset-2023-ufc/ufc_fight_stats.csv')\n",
    "ufc_fighters <- read.csv('/kaggle/input/mma-dataset-2023-ufc/ufc_fighters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data was scraped from the ufcstats.com. Unfortunately, it is not necessarily in the form needed for the models. Furthermore, the three datasets have useful statistics, and thus needed to be merged. For context, the ufc_stats data contains fight stats including striking output and control times, the ufc_fights data contains data on the fight such as weightclass and who won, the ufc_fighters data contain information on the fighters such as their reach and records.\n",
    "\n",
    "First, a full name variable was added for simplicity. Followng on from this, the datasets were merged and control/finish stats were changed to the right object type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-15T14:07:26.148075Z",
     "iopub.status.busy": "2023-09-15T14:07:26.145874Z",
     "iopub.status.idle": "2023-09-15T14:07:26.30576Z"
    },
    "trusted": true,
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# First, a full name column was created for simplicity\n",
    "ufc_fighters['fighter_fullname'] = ufc_fighters['fighter_f_name'] + ' ' + ufc_fighters['fighter_l_name']\n",
    "ufc_fighters = ufc_fighters.drop(columns=['fighter_f_name', 'fighter_l_name', 'fighter_dob'])\n",
    "\n",
    "# Then, the datasets were joined such that we had the fight and fighter stats for each fight\n",
    "df = ufc_fights.merge(ufc_stats, on='fight_id', how='outer').merge(ufc_fighters, on='fighter_id', how='outer')\n",
    "df = df.drop(columns=['fight_url', 'fighter_url'])  # Removed url columns as not relevant\n",
    "\n",
    "# We have a column on control time and finish time, but the MM:SS format is not ideal\n",
    "df['ctrl_time'] = df['ctrl_time'].replace('NULL', '0:00')\n",
    "df['finish_split'] = df['finish_time'].str.split(':')\n",
    "df['ctrl_split'] = df['ctrl_time'].str.split(':')\n",
    "df['finish_time'] = 60 * df['finish_split'].str[0].astype(int) + df['finish_split'].str[1].astype(int) + 300 * df['finish_round']\n",
    "df['ctrl_time'] = 60 * df['ctrl_split'].str[0].astype(int) + df['ctrl_split'].str[1].astype(int)\n",
    "df = df.drop(columns=['finish_split', 'ctrl_split'])\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have fight and fighter statistics merged for every fight. It is important to note that every fight is mirrored. What this means is that two consecutive rows depict the same fight, but contain in-fight statistics (striking, takedowns, submisions, control etc.) for each seperate fighter on one row each. To understand this, by looking at the fight_id column, we see that the first two rows have identical fight_id value (1), but the fighter_fight_id value differs (1 & 2). This is because row 1 contains in-fight data for Sean Daugherty, whereas row 2 contains in-fight data for Scott Morris.\n",
    "\n",
    "The next step was to add the opponent ID and opponent full name for each row. For context, f_1 and f_2 are variables which contain the ID number for both fighters. We assigned the opponent_id value by using the ID (f_1 or f_2) which did not match the fighter_id column. The opponent_fullname was then assigned by matching the opponent_id between df and ufc_fighters, pulling out the fullname for this ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-15T14:07:30.523345Z",
     "iopub.status.busy": "2023-09-15T14:07:30.521574Z",
     "iopub.status.idle": "2023-09-15T14:07:30.559881Z"
    },
    "trusted": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Setting opponent ID and fullname as NA\n",
    "df$opponent_id <- NA\n",
    "df$opponent_fullname <- NA\n",
    "\n",
    "# Detecting rows where fighter ID data is not available\n",
    "na_or_null <- is.na(df$f_1) | is.null(df$f_1)\n",
    "\n",
    "# Setting opponent ID, then pulling the full name by matching the ID\n",
    "df$opponent_id[!na_or_null] <- ifelse(df$f_1[!na_or_null] == df$fighter_id[!na_or_null], df$f_2[!na_or_null], df$f_1[!na_or_null])\n",
    "df$opponent_fullname <- ufc_fighters$fighter_fullname[match(df$opponent_id, ufc_fighters$fighter_id)]\n",
    "\n",
    "# Removing some irrelevant columns\n",
    "df <- df %>%\n",
    "  select(-c('referee', 'f_1', 'f_2', 'winner.x', 'num_rounds', 'weight_class_rank', 'result_details', 'finish_round',\n",
    "            'fighter_fight_id', 'fighter_nickname'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have done some of the more tedious work. Maybe you have noticed, but these statistics give us information from fights that have already happened, but we are interested in predicitng future outcomes in our project. This means that access to this data will not be available for our prediction, since the fight will not have already happened.\n",
    "\n",
    "This is where this project gets interesting, we need to create our own statistics which will be useful when predicting upcoming fights.\n",
    "\n",
    "Typical statistics use include striking, takedown, knockdown, submission (sub), reversal, control and finish time data.\n",
    "\n",
    "These statistics can be caculated in diffeent ways, including success percentage and average. Two functions were created, the first for calculating percentage accuracy, the second for simple average.\n",
    "\n",
    "Each fighter's percentage accuracy and average statistics were calculated over their whole career (I believe this gives the best representation of their output at any given time) and then added to a dataframe which can be merged with the base dataframe (df)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-15T14:07:45.117272Z",
     "iopub.status.busy": "2023-09-15T14:07:45.115489Z",
     "iopub.status.idle": "2023-09-15T14:08:45.903682Z"
    },
    "trusted": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Creating an empty data frame where statistics will be stored for each fighter\n",
    "my_stats_df <- data.frame(fighter_id = 1:nrow(ufc_fighters))\n",
    "\n",
    "# Mutating relevant variables into a numeric type\n",
    "df <- df%>%\n",
    "  mutate(across(c(knockdowns:ctrl_time), as.numeric))\n",
    "\n",
    "# Percentage accuracy function\n",
    "percentage.stat <- function(a,b,c,d){\n",
    "  for(i in 1:nrow(ufc_fighters)){\n",
    "    fighter.data <- subset(df, fighter_id == i)\n",
    "    for(j in 1:nrow(fighter.data)){\n",
    "      if(nrow(fighter.data)>0){\n",
    "        fighter.data[j,a] <- fighter.data[j,b]/fighter.data[j,c]\n",
    "        my_stats_df[i,d] <- mean(fighter.data[,a])\n",
    "        if(is.nan(my_stats_df[i,d])){\n",
    "          my_stats_df[i,d] <- 0\n",
    "        }else{\n",
    "        }\n",
    "      }else {\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  return(my_stats_df)\n",
    "}\n",
    "\n",
    "# Average function\n",
    "average.stat <- function(a,b){\n",
    "  for(i in 1:nrow(ufc_fighters)){\n",
    "    fighter.data <- subset(df, fighter_id == i)\n",
    "    if(nrow(fighter.data) > 0){\n",
    "      my_stats_df[i,a] <- mean(fighter.data[,b], na.rm = TRUE)\n",
    "      if(is.nan(my_stats_df[i,a])){\n",
    "        my_stats_df[i,a] <- NA\n",
    "      }else{\n",
    "      }\n",
    "    }else{\n",
    "    }\n",
    "  }\n",
    "  return(my_stats_df)\n",
    "}\n",
    "\n",
    "# Calculating percentage accuracy for strikes, significant strikes and takedowns\n",
    "my_stats_df <- percentage.stat('acc_strike', 'total_strikes_succ', 'total_strikes_att', 'strike_perc')\n",
    "my_stats_df <- percentage.stat('acc_sigstrike', 'sig_strikes_succ', 'sig_strikes_att', 'sigstrike_perc')\n",
    "my_stats_df <- percentage.stat('acc_td', 'takedown_succ', 'takedown_att', 'takedown_perc')\n",
    "\n",
    "# Calculating average for strikes, significant strikes, knockdowns, takedowns, submission attempts, reversals, control and finish time\n",
    "my_stats_df <- average.stat('strike_avg', 'total_strikes_succ')\n",
    "my_stats_df <- average.stat('sig_strike_avg', 'sig_strikes_succ')\n",
    "my_stats_df <- average.stat('knockdown_avg', 'knockdowns')\n",
    "my_stats_df <- average.stat('takedown_avg', 'takedown_succ')\n",
    "my_stats_df <- average.stat('sub_avg', 'submission_att')\n",
    "my_stats_df <- average.stat('reversal_avg', 'reversals')\n",
    "my_stats_df <- average.stat('control_avg', 'ctrl_time')\n",
    "my_stats_df <- average.stat('finish_avg', 'finish_time')\n",
    "\n",
    "# We then calculate the average strikes and significant strikes per minute\n",
    "my_stats_df <- my_stats_df %>%\n",
    "  mutate(strike_per_minute = strike_avg/(finish_avg/60), sig_strike_per_minute = sig_strike_avg/(finish_avg/60))\n",
    "\n",
    "# We also calculated win percentage\n",
    "my_stats_df <- my_stats_df %>%\n",
    "  mutate(win_perc = (ufc_fighters$fighter_w)/(rowSums(ufc_fighters[,7:9])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now create a new dataframe such that it contains the opponent's fight statistics, making it easier to merge.\n",
    "\n",
    "We then merge the three dataframes such that on one row we have fight statistics, in-fight statistics, fighter statistics and opponent statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-15T14:10:46.450748Z",
     "iopub.status.busy": "2023-09-15T14:10:46.448911Z",
     "iopub.status.idle": "2023-09-15T14:10:46.502935Z"
    },
    "trusted": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Opponent stat dataframe\n",
    "opp_stats_df <- my_stats_df\n",
    "for(i in 2:ncol(opp_stats_df)){\n",
    "  colnames(opp_stats_df)[i] <- paste0('opp_', colnames(my_stats_df[i]))\n",
    "}\n",
    "\n",
    "# Joining the dataframes\n",
    "df <- df %>%\n",
    "  full_join(my_stats_df, by = 'fighter_id')%>%\n",
    "  full_join(opp_stats_df, by = c('opponent_id' = 'fighter_id'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating stat differentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-15T14:10:50.168778Z",
     "iopub.status.busy": "2023-09-15T14:10:50.16684Z",
     "iopub.status.idle": "2023-09-15T14:10:50.320488Z"
    },
    "trusted": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Calculating differentials\n",
    "df <- df %>%\n",
    "  mutate(strike_diff = strike_avg - opp_strike_avg, sig_strike_diff = sig_strike_avg - opp_sig_strike_avg,\n",
    "         spm_diff = strike_per_minute - opp_strike_per_minute, sspm_diff = sig_strike_per_minute - opp_sig_strike_per_minute,\n",
    "         knockdown_diff = knockdown_avg - opp_knockdown_avg, takedown_diff = takedown_avg - opp_takedown_avg,\n",
    "         sub_diff = sub_avg - opp_sub_avg, control_diff = control_avg - opp_control_avg)\n",
    "\n",
    "# Removing some columns which are now not useful, Ordering data frame as wanted.\n",
    "df <- df %>%\n",
    "  select(-c('fighter_d', 'fighter_l', 'fighter_nc_dq'))%>%\n",
    "  select(event_id, fight_id, fighter_id, fighter_fullname, fighter_age, fighter_height_cm:fighter_stance, \n",
    "         title_fight, weight_class, gender, winner.y, result: finish_time, total_strikes_att:ctrl_time, strike_perc:win_perc,\n",
    "         fighter_w, opponent_id, opponent_fullname, opp_strike_perc:control_diff)%>%\n",
    "  mutate(across(fighter_age:fighter_reach_cm, as.numeric))# Changing variable types to numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As visible in th table above, there seems to be a lot of missing data. A quick visualisation of NA values location reveals that most of these are located in the earlier section of the dataframe. This is because he UFC did not consistently track metrics such as age, reach, height and control time in the earlier stages of the organisation. A decision was made to remove rows with NA values. This decision was based around 2 reasons:\n",
    "* For simplicity - removing NA values will facilitate the use of machine learning models\n",
    "* Old data -  this data is fairly old, dating back to the early 2000s, thus may not be very useful for predicting fight outcomes some 20 years later.\n",
    "\n",
    "Removing this data led to a reduction of 10.7%, which is substantial, but makes sense. Originally, the ufc_stats dataframe, which contains in-fight statistics was made up of 14148 rows, our reduced df dataframe contains 12626 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-15T14:10:56.108222Z",
     "iopub.status.busy": "2023-09-15T14:10:56.106234Z",
     "iopub.status.idle": "2023-09-15T14:10:58.980446Z"
    },
    "trusted": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Visualising Location of NA Values\n",
    "library(Amelia)\n",
    "missmap(df, col = c('yellow', 'black')) # The yellow lines at the top represent the missing values from earliest fights. The large yellow block at the bottom is representative of rows corresponding to fighters who have not fought in the UFC, so data is not useful either.\n",
    "\n",
    "# Removing rows with NA values\n",
    "df <- na.omit(df)\n",
    "\n",
    "# Removing NULL values to Unknown, then changin variables types from character to factor\n",
    "df$fighter_stance <- ifelse(df$fighter_stance == 'NULL', 'Unknown', df$fighter_stance)\n",
    "df$weight_class <- ifelse(df$weight_class == 'NULL' | is.na(df$weight_class), 'Unknown', df$weight_class)\n",
    "df <- df %>%\n",
    "  mutate(weight_class = factor(weight_class, levels = c(\"Women's Strawweight\", \"Women's Flyweight\", \"Women's Bantamweight\", \n",
    "                                                        \"Women's Featherweight\", \"Flyweight\", 'Bantamweight', 'Featherweight', \n",
    "                                                        'Lightweight', 'Welterweight', 'Middleweight', 'Light Heavyweight', \n",
    "                                                        'Heavyweight', 'Catch Weight', 'Open Weight', 'Unknown')))%>%\n",
    "  mutate(across(c('fighter_stance', 'title_fight', 'gender', 'winner.y', 'result'), as.factor))\n",
    "\n",
    "dim(df) # 12626 x 63 \n",
    "dim(ufc_stats) # 14148 x 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step involved calculating a new set of statistics. First, the original data contains overall records, whereas UFC record should be used for our models, due to the level of competition outside of the UFC potentially leading to an inflation in the number of victories for fighters. Thus, the number of wins within the UFC was calculated for a more accurate representation of the fighters' success within the organisation.\n",
    "\n",
    "Next, the form of the fighter was calculated, both before the fight and after the fight. Essentially, the last 5 fights were used (or last however many if the fighter does not have 5 fights in the UFC), a victory scores 1 point, whilst a loss gives you -1. Therefore, a fighter who is 3-2 in their last 5 scores a 1, whereas a fighter who is 1-4 scores -3. The calculation for the last 5 form after the fight was performed for simplicity later down the line.\n",
    "\n",
    "Similarly, the streak before and after the fight was calculated. A streak of 8 wins scores an 8, whereas a losing streak of 3 fights score a -3. When a fighter loses a winning streak, their streak is changed to -1, and vice versa when breaking a losing streak, their streak is updated to 1.\n",
    "\n",
    "(newlast5 and newstreak variables will not be used in models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-15T14:11:06.950899Z",
     "iopub.status.busy": "2023-09-15T14:11:06.948945Z",
     "iopub.status.idle": "2023-09-15T14:12:26.734336Z"
    },
    "trusted": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Calculating wins with the UFC\n",
    "full_df <- data.frame()\n",
    "for(name in unique(df$fighter_fullname)){\n",
    "  fighter_df <- df %>%\n",
    "    filter(fighter_fullname == name)\n",
    "  for(i in 1:nrow(fighter_df)){\n",
    "    fighter_df$fighter_w[i] <- sum(fighter_df$winner.y[0:(i-1)] == 'T')\n",
    "  }\n",
    "  full_df <- rbind(full_df, fighter_df)\n",
    "}\n",
    "df <- full_df # Actual fighter_w\n",
    "\n",
    "# Calculating form from last 5 fights\n",
    "full_df <- data.frame()\n",
    "for(name in unique(df$fighter_fullname)){\n",
    "  vector <- c()\n",
    "  fighter_df <- df %>%\n",
    "    filter(fighter_fullname == name)\n",
    "  for(i in 1:nrow(fighter_df)){\n",
    "    if(i <4){\n",
    "      newlast5 <- sum(fighter_df[0:(i), 'winner.y'] == 'T') - sum(fighter_df[0:(i), 'winner.y'] == 'F')\n",
    "    }else{\n",
    "      newlast5 <- sum(fighter_df[(i-4):(i), 'winner.y'] == 'T') - sum(fighter_df[(i-4):(i), 'winner.y'] == 'F')\n",
    "    }\n",
    "    vector[i] <- newlast5\n",
    "  }\n",
    "  fighter_df$last5 <- append(vector[-length(vector)], 0, 0) # last5 = last 5 fights form before fight\n",
    "  fighter_df$newlast5 <- vector # newlast5 = updated last 5 fights form after fight\n",
    "  full_df <- rbind(full_df, fighter_df)\n",
    "} # last 5 fight form (before and after fight)\n",
    "df <- full_df\n",
    "\n",
    "# Calculating the streak\n",
    "full_df <- data.frame()\n",
    "for(name in unique(df$fighter_fullname)){\n",
    "  streak <- 0\n",
    "  full_streak <- c()\n",
    "  fighter_df <- df%>%\n",
    "    filter(fighter_fullname == name)\n",
    "  for(j in 1:nrow(fighter_df)){\n",
    "    if(streak == 0){\n",
    "      if(fighter_df$winner.y[j] == 'T'){\n",
    "        streak <- 1\n",
    "      }else{\n",
    "        streak <- -1\n",
    "      }\n",
    "    }else if(streak<0){\n",
    "      if(fighter_df$winner.y[j] == 'T'){\n",
    "        streak <- 1\n",
    "      }else{\n",
    "        streak <- streak - 1\n",
    "      }\n",
    "    }else{\n",
    "      if(fighter_df$winner.y[j] == 'T'){\n",
    "        streak <- streak + 1\n",
    "      }else{\n",
    "        streak <- -1\n",
    "      }\n",
    "    }\n",
    "    full_streak <- append(full_streak, streak)\n",
    "  }\n",
    "  fighter_df$streak <- append(full_streak[-length(full_streak)],0,0) # streak = streak before fight\n",
    "  fighter_df$newstreak <- full_streak # newstreak = streak after fight\n",
    "  full_df <- rbind(full_df, fighter_df)\n",
    "}\n",
    "df <- full_df\n",
    "\n",
    "# Making a copy of current df dataframe\n",
    "full_df <- df\n",
    "\n",
    "head(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are done with feature engineering, we have calculated a range of interesting statistics and changed their types to the appropriate  structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is still an issue with the df dataset, many of the fights are duplicated, as in we have the statistics for each fighter for the same fight. The issue with this is that you are at risk of heavily correlating error terms, since if one win, the other must lose. We also won't be able to calculate true accuracy and precision\n",
    "\n",
    "In this section, the dataset was reduced such that the only 1 side of each fight is included. Particular attention was drawn to having equal amount of winner.y = TRUE (won the fight) as winner.y = FALSE (lost the fight) such that the models do not have a bias in predicting losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-15T14:13:45.206508Z",
     "iopub.status.busy": "2023-09-15T14:13:45.20452Z",
     "iopub.status.idle": "2023-09-15T14:13:45.35446Z"
    },
    "trusted": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# For replicating results\n",
    "set.seed(5550)\n",
    "\n",
    "# Finding fights which have stats for both fighters (some only have stats for 1)\n",
    "duplicated_fights <- duplicated(df$fight_id) | duplicated(df$fight_id, fromLast = T)\n",
    "\n",
    "# Creating dataframe of fights which are not uplicated\n",
    "df.unique.fights <- df[!duplicated_fights,] \n",
    "df.duplicated.fights <- df[duplicated_fights,] # Automatically using those fights for our final dataframe\n",
    "\n",
    "# Getting random sample from remaining fights, ensuring TRUE and FALSE are equally spread\n",
    "sample <- sample(unique(df.duplicated.fights$fight_id), ((length(unique(df$fight_id))/2)-sum(df.unique.fights$winner.y == 'T')), replace = FALSE)\n",
    "df.duplicated.winners <- df.duplicated.fights %>%\n",
    "  filter(winner.y == 'T')%>%\n",
    "  subset(fight_id%in%sample)\n",
    "df.duplicated.losers <- df.duplicated.fights %>%\n",
    "  filter(winner.y == 'F')%>%\n",
    "  subset(!fight_id%in%sample)\n",
    "df <- rbind(df.unique.fights,df.duplicated.winners, df.duplicated.losers)%>%\n",
    "  arrange(fight_id)\n",
    "\n",
    "# Checking we have an equal spread\n",
    "dim(df) # 6707 x 67 (6707 unique fights)\n",
    "sum(df$winner.y == 'T') # 3353 of those fights contain stats on winning fighter stats\n",
    "\n",
    "# Removing some final columns\n",
    "df <- df%>%\n",
    "  select(-event_id, -(total_strikes_att:ctrl_time), -finish_time, -newlast5, -newstreak)\n",
    "\n",
    "head(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is ready to be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some Data visualisation work was carried out, with some being made to visualise and understand potential impactful variables on winning, and others just for fun and practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-15T14:14:00.437155Z",
     "iopub.status.busy": "2023-09-15T14:14:00.433323Z",
     "iopub.status.idle": "2023-09-15T14:14:00.96009Z"
    },
    "trusted": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Visualising if significant strike output impacts winning\n",
    "ggplot(df, aes(x = winner.y, y = sspm_diff, fill = winner.y)) + geom_boxplot() + theme_economist_white() + labs(x = 'Victory?', y = 'Difference in Significant Strikes per Minute', title = 'Difference in Striking Output') + scale_fill_discrete(guide = guide_legend('Winner?', legend.position = 'top'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-15T14:14:03.34336Z",
     "iopub.status.busy": "2023-09-15T14:14:03.340976Z",
     "iopub.status.idle": "2023-09-15T14:14:03.927321Z"
    },
    "trusted": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Finding if there are any discrepancies between males and females in fighting stance. This also allows us to visualise if the stance impacts winning.\n",
    "df %>%\n",
    "  filter(fighter_stance != 'Open Stance' & fighter_stance != 'Unknown')%>%\n",
    "  ggplot(aes(x = fighter_stance, fill = winner.y)) + geom_bar(col = 'black', position = 'fill') + scale_fill_discrete(guide = guide_legend('Gender', title.position = 'bottom',label.position = 'top')) + theme(legend.position = 'top') + facet_grid(.~gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-15T14:14:05.908173Z",
     "iopub.status.busy": "2023-09-15T14:14:05.901988Z",
     "iopub.status.idle": "2023-09-15T14:14:07.266165Z"
    },
    "trusted": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Plotting average age by weightclass\n",
    "myplot <- df%>%\n",
    "  group_by(weight_class)%>%\n",
    "  mutate(mean_age = mean(fighter_age))%>%\n",
    "  ungroup()%>%\n",
    "  mutate(overall.mean.age = mean(fighter_age))%>%\n",
    "  filter(weight_class != 'Open Weight' & weight_class != 'Unknown')%>%\n",
    "  ggplot(aes(x = fighter_age, y = weight_class)) + geom_jitter(aes(col = weight_class), alpha = 0.5) + \n",
    "  geom_vline(xintercept = mean(df$fighter_age),lty = 2, lwd = 1) + \n",
    "  geom_segment(aes(x = mean_age, xend = mean(fighter_age), y = weight_class, yend = weight_class)) +\n",
    "  stat_summary(geom = 'point', size = 6, fun = mean, col = 'black')\n",
    "myplot # There aren't any particular differences, maybe fighters ge older for heavier weight classes? looks colourful though"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepping Training and Test Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When carrying out Machine Learning, it is important to separate the whole dataset into a training portion and a test portion. For this project, a 70/30 ratio was used, guaranteeing that enough data was available for training whilst having a large enough sample for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-15T14:14:52.429915Z",
     "iopub.status.busy": "2023-09-15T14:14:52.427608Z",
     "iopub.status.idle": "2023-09-15T14:14:52.471319Z"
    },
    "trusted": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Removing irrelevant columns\n",
    "df <- df%>%\n",
    "  select(-c(fight_id:fighter_fullname, result, opponent_id, opponent_fullname)) # Final selection of variables\n",
    "df_save <- df # Making a copy, useful later\n",
    "\n",
    "# Training and Test Data\n",
    "set.seed(123)\n",
    "split <- sample.split(df$winner.y, SplitRatio = 0.7)\n",
    "training <- subset(df, split == TRUE)\n",
    "test <- subset(df, split == FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forest Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tree methods are useful, but somewhat limited when intricate trends need to be identifies. A Random Forest method is a good alternative as it combines multiple trees which are trained on different portions of the training dataset and having only part of the variables for each split.\n",
    "\n",
    "The number of wins and control differential were given particular importance as, intuitively, they should reflect the fighter's probability of winning fairly well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-15T14:15:02.759236Z",
     "iopub.status.busy": "2023-09-15T14:15:02.756313Z",
     "iopub.status.idle": "2023-09-15T14:15:31.96274Z"
    },
    "trusted": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "set.seed(101)\n",
    "forest <- randomForest(data = training, winner.y ~.  + I(fighter_w)^2 + I(control_diff)^2 - fighter_stance - fighter_age -\n",
    "                         fighter_height_cm - finish_avg, importance = TRUE, method = 'class') # fighter_w\n",
    "forest$importance # This gives you insight into the most infleuncial predictor/variable (MeanDecreaseGini higher = more impact)\n",
    "forest.pred <- predict(forest, test, method = 'class')\n",
    "table(forest.pred, test$winner.y)\n",
    "confidence.forest <- mean(forest.pred == test$winner.y)\n",
    "precision.forest <- table(forest.pred, test$winner.y)[2,2]/(rowSums(table(forest.pred, test$winner.y))[2])\n",
    "confidence.forest # 70%\n",
    "precision.forest # 71%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine Models aim to create a decision boundary based on the data by using support vectors. Essentially, it chooses (you can choose this manually) a number of points in the multidimensional space as key points. The model then attempts to separate these points through a decision boundary, this can be a linear, radial or polynomial boundary.\n",
    "\n",
    "In large datasets with many predictors, it is very often impossible to completely separate these points through a boundary, thus the model allows missclassifications in order to produce this boundary. This means that some of the data points may purposely be allowed to be misclassified by your decision boundary in order to benefit the model as a whole. The number of missclassifications can be controlled by controlling the 'cost'. A low cost allows a lot of missclassification.\n",
    "\n",
    "To decide on the decision boundary, the model follows this process. Since missclassifications are allowed, the model can produce many decision lines/curves which separate the data into two categories (in our case, TRUE and FALSE) based on the predictors. The model then produces a margin between the decision line/curve and the support vectors, such that the margin extends to the support vector. We then choose the decision line/curve which maximizes this margin as the decision boundary.\n",
    "\n",
    "By increasing the number of missclassifications (decreasing the cost), we allow the model to be more robust to changes in data, but you also increase your bias. Similarly, by increasing your cost, which decreases the number of missclassifications, your model is mor susceptible to changes in data but your bias is lower. You must strike a good balance between the two.\n",
    "\n",
    "In this model, a radial kernel (decision boundary) was utilised due to the complexity of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-15T14:15:51.44233Z",
     "iopub.status.busy": "2023-09-15T14:15:51.440448Z",
     "iopub.status.idle": "2023-09-15T14:15:58.812736Z"
    },
    "trusted": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "set.seed(123)\n",
    "mysvm <- svm(data = training, winner.y ~. + I(fighter_w)^2 + I(control_diff)^2 - fighter_stance - fighter_age -\n",
    "               fighter_height_cm, kernel = 'radial')\n",
    "svm.pred <- predict(mysvm, test)\n",
    "table(svm.pred, test$winner.y)\n",
    "confidence.svm <- mean(svm.pred == test$winner.y)\n",
    "precision.svm <-  table(svm.pred, test$winner.y)[2,2]/(rowSums(table(svm.pred, test$winner.y))[2])\n",
    "confidence.svm # 71%\n",
    "precision.svm # 72%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression Models are some of the simpler classifier models, which is what is investeigated in this project. The Logistic Regression Model functions in the following way:\n",
    "* Fitting curves - since we only have two outcomes, the model attempts to adjust predictor coefficients such that it produces a curve (once data has been passed through a logit link function) which attempts to correctly match the TRUE and FALSE points.\n",
    "* Maximizes the likelihood function - the likelihood function (LF) expresses the probability that the data points are distributed as per thye data if the function assumed in previous step is true. Thus, by maximizing the LF, we can find preditor coefficients which are most likely to result in the training data results.\n",
    "* Classifies test data - Once we have our function, the test data can be classified by calculating the probability of the data point being in the class of interest. Once above a threshold (usually 0.5/50%, but can be chosen), the data point will be classified as the class of interest.\n",
    "\n",
    "In this section, we investigate this model and how the decision threshold affects the accuracy/precision of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-15T14:16:12.657921Z",
     "iopub.status.busy": "2023-09-15T14:16:12.656104Z",
     "iopub.status.idle": "2023-09-15T14:19:15.373152Z"
    },
    "trusted": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "set.seed(123)\n",
    "logmodel <- glm(data = training, winner.y ~. + I(fighter_w)^2 + I(control_diff)^2, family = binomial(link = logit))\n",
    "logmodel <- step(logmodel)\n",
    "\n",
    "# Investigating impact of decision threshold on accuracy/confidence\n",
    "confidence.log <- c()\n",
    "for(i in seq(min(0.4), max(0.6), by = 0.01)){\n",
    "  log.pred <- predict(logmodel, test, type = 'response')\n",
    "  log.pred <- ifelse(log.pred > i, 'T', 'F')\n",
    "  confidence.log <- append(confidence.log, mean(log.pred == test$winner.y))\n",
    "}\n",
    "plot(seq(min(0.4), max(0.6), by = 0.01),confidence.log)\n",
    "lines(seq(min(0.4), max(0.6), by = 0.01),confidence.log) # max accuracy at i = 0.51\n",
    "\n",
    "# Setting decision threshold at 0.51 (peak accuracy)\n",
    "log.pred <- predict(logmodel, test, type = 'response')\n",
    "log.pred <- ifelse(log.pred > 0.51, 'T', 'F')\n",
    "confidence.log <- mean(log.pred == test$winner.y)\n",
    "precision.log <- table(log.pred, test$winner.y)[2,2]/(rowSums(table(log.pred, test$winner.y))[2])\n",
    "confidence.log # 70%\n",
    "precision.log # 71%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network is a method of deep learning which is complicated and I do not have enough knowledge to explain it accurately. In short, it uses a number of nodes and adjusts weights of predictors based on the accuracy of the previous predictions.\n",
    "\n",
    "In Neural Networks, it is important to scale your data, such that not one is considered more important than the other originally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-15T14:20:00.607149Z",
     "iopub.status.busy": "2023-09-15T14:20:00.605287Z",
     "iopub.status.idle": "2023-09-15T14:20:20.547184Z"
    },
    "trusted": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Scaling training and testing dataframes\n",
    "scaled.df <- df%>%\n",
    "  select(-c(fighter_stance:gender, winner.y))%>% # removing factors\n",
    "  scale()%>%\n",
    "  data.frame()%>%\n",
    "  mutate(winner.y = df$winner.y)\n",
    "\n",
    "set.seed(123)\n",
    "split <- sample.split(scaled.df$winner.y, SplitRatio = 0.7)\n",
    "scaled.training <- subset(scaled.df, split == TRUE)\n",
    "scaled.test <- subset(scaled.df, split == FALSE)\n",
    "\n",
    "# Model\n",
    "n <- names(scaled.training)\n",
    "f <- as.formula(paste(\"winner.y ~\", paste(n[!n %in% \"winner.y\"], collapse = \" + \")))\n",
    "nn <- neuralnet(data = scaled.training, f, linear.output = FALSE)\n",
    "nn.pred <- predict(nn, scaled.test[,-ncol(scaled.test)])\n",
    "nn.pred <- ifelse(nn.pred[,2] >0.5, 'T', 'F')\n",
    "table(nn.pred, scaled.test$winner.y)\n",
    "confidence.nn <- mean(nn.pred == scaled.test$winner.y)\n",
    "precision.nn <- table(nn.pred, test$winner.y)[2,2]/(rowSums(table(nn.pred, test$winner.y))[2])\n",
    "confidence.nn # 70%\n",
    "precision.nn # 71%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-15T13:04:11.417896Z",
     "iopub.status.busy": "2023-09-15T13:04:11.41482Z",
     "iopub.status.idle": "2023-09-15T13:04:11.43597Z"
    }
   },
   "source": [
    "### Final Function And Prediction Times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models have now been built and we are ready to predict fight outcomes. All you need to input are the fighter names, TRUE/FALSE (whetehr it is a title fight or not), M/F (for gender), the weightclass and the model of choice.\n",
    "\n",
    "The options for the model are:\n",
    "* mysvm - Support Vector Machine (type in mysvm as final argument in function)\n",
    "* forest - Random Forest\n",
    "* logmodel - Logistic Regression\n",
    "* nn - Neural Network\n",
    "\n",
    "Please ensure to correctly write the fighter's names and weightclass (if you go back up, the correct spelling will be available where the weight class predictor was converted from character to factor type).\n",
    "\n",
    "Also bare in mind the fact that some fighters are not in the original database since they had not made their debut yet. Another thing where you have to be careful is when choosing a fighter who's name may be replaced with their nicknam (Mike Matheta Diamond = Blood Diamon in the dataset), or have multiple names within their names, the original dataset may only include a part of the whole name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-15T14:20:41.737845Z",
     "iopub.status.busy": "2023-09-15T14:20:41.735724Z",
     "iopub.status.idle": "2023-09-15T14:20:41.756086Z"
    },
    "trusted": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Creating the Function\n",
    "my.function <- function(a, b, title, gender, category, model){\n",
    "  fighter_names <- unique(full_df$fighter_fullname)\n",
    "  get_fighter1_data <- function(name) {\n",
    "    fighter_data <- full_df %>%\n",
    "      filter(fighter_fullname == name) %>%\n",
    "      slice_max(fight_id)\n",
    "    return(fighter_data)\n",
    "  }\n",
    "  get_fighter2_data <- function(name){\n",
    "    fighter_data <- full_df %>%\n",
    "      filter(opponent_fullname == name) %>%\n",
    "      slice_max(fight_id)\n",
    "    return(fighter_data)\n",
    "  }\n",
    "  \n",
    "  if(a%in%fighter_names & b%in%fighter_names){\n",
    "    get_prediction <- function(a,b){\n",
    "      fighter1 <- get_fighter1_data(a)%>%\n",
    "        select(fighter_age:fighter_stance, strike_perc:fighter_w, newstreak, newlast5)%>%\n",
    "        rename(last5 = newlast5, streak = newstreak)\n",
    "      fighter2 <- get_fighter2_data(b)%>%\n",
    "        select(opp_strike_perc:opp_win_perc)\n",
    "      \n",
    "      df <- cbind(fighter1, fighter2)\n",
    "      df <- df %>%\n",
    "        mutate(strike_diff = strike_avg - opp_strike_avg, sig_strike_diff = sig_strike_avg - opp_sig_strike_avg,\n",
    "               spm_diff = strike_per_minute - opp_strike_per_minute, sspm_diff = sig_strike_per_minute - opp_sig_strike_per_minute,\n",
    "               knockdown_diff = knockdown_avg - opp_knockdown_avg, takedown_diff = takedown_avg - opp_takedown_avg,\n",
    "               sub_diff = sub_avg - opp_sub_avg, control_diff = control_avg - opp_control_avg)\n",
    "      df$title_fight <- factor(title, levels = c('FALSE', 'TRUE'))\n",
    "      df$gender <- factor(gender, levels = c('F', 'M'))\n",
    "      df$weight_class <- factor(category, levels = c(\"Women's Strawweight\", \"Women's Flyweight\", \"Women's Bantamweight\", \n",
    "                                                     \"Women's Featherweight\", \"Flyweight\", 'Bantamweight', 'Featherweight', \n",
    "                                                     'Lightweight', 'Welterweight', 'Middleweight', 'Light Heavyweight', \n",
    "                                                     'Heavyweight', 'Catch Weight', 'Open Weight', 'Unknown'))\n",
    "      \n",
    "      if(identical(model, nn)){\n",
    "        df <- df_save%>%\n",
    "          select(-winner.y)%>%\n",
    "          rbind(df)%>%\n",
    "          select(-c(fighter_stance:gender))%>% # removing factors\n",
    "          scale()%>%\n",
    "          data.frame()%>%\n",
    "          tail(1)\n",
    "        prediction <- predict(nn, df)\n",
    "        prediction <- ifelse(prediction[,2] >0.5, 'T', 'F')\n",
    "      }else{\n",
    "        prediction <- predict(model, df)\n",
    "        if(identical(model, logmodel)){\n",
    "          prediction <- ifelse(prediction>0.52, 'T', 'F')\n",
    "        }\n",
    "      }\n",
    "      return(prediction)\n",
    "    }\n",
    "    \n",
    "    prediction <- get_prediction(a,b)\n",
    "    prediction.bis <- get_prediction(b,a)\n",
    "    \n",
    "    models <- list(\n",
    "      mysvm = c(confidence.svm, precision.svm, 'Support Vector Machine Model'),\n",
    "      forest = c(confidence.forest, precision.forest, 'Random Forest Model'),\n",
    "      logmodel =c(confidence.log, precision.log, 'Logistic Regression Model'),\n",
    "      nn = c(confidence.nn, precision.nn, 'Neural Network Model')\n",
    "    )\n",
    "    model <- deparse(substitute(model))\n",
    "    confidence <- as.numeric(models[[model]][1])\n",
    "    precision <- as.numeric(models[[model]][2])\n",
    "    model <- models[[model]][3]\n",
    "    \n",
    "    if(prediction == prediction.bis){\n",
    "      if(prediction == 'T'){ # 2 is the factor level of TRUE\n",
    "        print(\"Sorry, I can't accurately predict this fight, I feel like both should win ;)\")\n",
    "      }else{\n",
    "        print(\"Sorry, I can't accurately predict this fight, I feel like both will lose :(\")\n",
    "      }\n",
    "    }else if(prediction == 'T'){\n",
    "      paste0('I predict ', a,  ' wins this fight. This has been predicted using a ', model, ' with ', round(confidence*100), '% confidence and ', round(precision*100), '% precision')\n",
    "    }else{\n",
    "      paste0('I predict ', b,  ' wins this fight. This has been predicted using a ', model, ' with ', round(confidence*100), '% confidence and ', round(precision*100), '% precision')\n",
    "    }\n",
    "  }else{\n",
    "    if(!a%in%fighter_names & !b%in%fighter_names){\n",
    "      cat('Sorry, I do not have data on either fighters, did you spell them correctly?')\n",
    "    }else if(a%in%fighter_names){\n",
    "      cat('Sorry I do not have data on', b, 'unfortunately, have you spelt it correctly?')\n",
    "    }else{\n",
    "      cat('Sorry, I do not have data on', a, 'unfortunately, have you spelt it correctly?')\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the function on various fictitious fights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-15T14:20:46.258883Z",
     "iopub.status.busy": "2023-09-15T14:20:46.257009Z",
     "iopub.status.idle": "2023-09-15T14:20:46.828882Z"
    },
    "trusted": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "my.function(\"Sean O'Malley\", \"Aljamain Sterling\", 'TRUE', 'M', \"Bantamweight\", mysvm)\n",
    "my.function(\"Jon Jones\", \"Francis Ngannou\", 'TRUE', 'M', \"Heavyweight\", forest) \n",
    "my.function(\"Paddy Pimblett\", \"Charles Oliveira\", 'FALSE', 'M', \"Lightweight\", logmodel)\n",
    "my.function(\"Erin Blanchfield\", \"Alexa Grasso\", 'TRUE', 'F', \"Women's Flyweight\", nn)\n",
    "# This fight is not in the original dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the end of the project, it has been very fun to make and share.\n",
    "\n",
    "For a first project, I think I have been able to dip my toes into a range of different aspects of coding and Machine Learning. Plenty of work remains to be done on optimising my code and the models, but I can't wait to see the progression.\n",
    "\n",
    "I doubt anybody will see this project to be honest, but if you do, please please give me some feedback, I would honestly appreciate it so much.\n",
    "\n",
    "One main drawback of this project is the fact that the dataset does not include a metric to represent the level of competition faced. This may explain the Paddy Pimblett vs Charles Oliveira prediction. In short, Paddy Pimblett has fought low-level fighters, and thus his stats are inflated, whereas Charles Oliveira has gone against the best, so his stats will not look as good. To counter this, the total wins predictor (winner.y) was given higher importance since this would reflect the longevity and quality of the fighter, but of course it won't be enough sometimes to push the balance on one side."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 3530899,
     "sourceId": 6608554,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30530,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "r",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
